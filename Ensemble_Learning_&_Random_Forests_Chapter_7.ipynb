{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble Learning & Random Forests Chapter 7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfcchvJNVAJbGJQfRBLlll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AashiDutt/Hands-on-Machine-Learning-with-sklearn-keras-and-tensorflow/blob/main/Ensemble_Learning_%26_Random_Forests_Chapter_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZWP3h3V9mb_e"
      },
      "outputs": [],
      "source": [
        "# Creating an ensemble of 3 classifiers\n",
        "\n",
        "# Imports\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC # support vector machine\n",
        "from sklearn.ensemble import VotingClassifier # used for voting for best classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_moons(n_samples = 500, noise= 0.30, random_state = 42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n"
      ],
      "metadata": {
        "id": "RifHcI-noce7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_clf = LogisticRegression(solver = \"lbfgs\", random_state = 42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
        "svm_clf = SVC(gamma = \"scale\", random_state = 42)"
      ],
      "metadata": {
        "id": "y-ChDvN9nXep"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# test with hard voting i.e  majority voting.\n",
        "\n"
      ],
      "metadata": {
        "id": "O78hQVYjqqMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf = VotingClassifier(\n",
        "    estimators= [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting = \"hard\"  \n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWQ7uFp2n0kw",
        "outputId": "a3c82ac7-63b5-4dce-d65d-eea8bd3cdf3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__, accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Yc22P_pWsx",
        "outputId": "269d3aeb-edf9-42cc-c26a-1458fa9fe688"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.linear_model._logistic.LogisticRegression'> 0.864\n",
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'> 0.896\n",
            "<class 'sklearn.svm._classes.SVC'> 0.896\n",
            "<class 'sklearn.ensemble._voting.VotingClassifier'> 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test with soft voting i.e to predict the class with highest class probability averaged over all individual classifiers."
      ],
      "metadata": {
        "id": "C9HhbpUfqwGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_clf = LogisticRegression(solver = \"lbfgs\", random_state = 42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
        "svm_clf = SVC(gamma = \"scale\",probability = True, random_state = 42)"
      ],
      "metadata": {
        "id": "96X3GVOBpxWo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf = VotingClassifier(\n",
        "    estimators= [('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)], voting = \"soft\"  \n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b_bVf8crM0H",
        "outputId": "61e139c1-039e-41c3-aedd-b85f7cfec4d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(probability=True, random_state=42))],\n",
              "                 voting='soft')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soBHO7NprQtG",
        "outputId": "250f8feb-9bed-4cb3-e834-d1e78d7f8203"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'sklearn.linear_model._logistic.LogisticRegression'> 0.864\n",
            "<class 'sklearn.ensemble._forest.RandomForestClassifier'> 0.896\n",
            "<class 'sklearn.svm._classes.SVC'> 0.896\n",
            "<class 'sklearn.ensemble._voting.VotingClassifier'> 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging(Bootstrap Aggregating) and Pasting\n",
        "\n",
        "Bagging - when sampling is performed with replacement i.e instead of using different algorithms for every predictor, we use same training algorithm and train them on different random subsets of training set.\n",
        "\n",
        "Pasting - when sampling is performed without replacement\n",
        "\n",
        "Bagging and pasting scale very well."
      ],
      "metadata": {
        "id": "yktPwOgG-Xjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# n_estimators - no. of trees, 100 training instances, bootstrap(bagging) = True / False for Pasting , n_jobs - cpu cores\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators = 500, max_samples = 100, bootstrap = True, n_jobs = 1 )\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "FzvcnA9r-GYL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Out of bag evaluation (oob) are the instances that are not included in the training instance due to replacement. Instead they can be used for validation\n",
        "\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators = 500, bootstrap = True, n_jobs = 1 , oob_score = True)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c7fyUsMDiTj",
        "outputId": "66c037e8-f483-43eb-bce1-fb5d98f98419"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9013333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets verify using test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgg0lVSEvbO",
        "outputId": "6cd139d3-9ba7-47c0-fefc-8d35745b328b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.904"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVfGMEewFClr",
        "outputId": "3142ea4d-7b12-4871-ccea-a331885a0bdd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37634409, 0.62365591],\n",
              "       [0.33526012, 0.66473988],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07853403, 0.92146597],\n",
              "       [0.36413043, 0.63586957],\n",
              "       [0.00520833, 0.99479167],\n",
              "       [0.99468085, 0.00531915],\n",
              "       [0.97814208, 0.02185792],\n",
              "       [0.8030303 , 0.1969697 ],\n",
              "       [0.00574713, 0.99425287],\n",
              "       [0.82758621, 0.17241379],\n",
              "       [0.84126984, 0.15873016],\n",
              "       [0.96174863, 0.03825137],\n",
              "       [0.02604167, 0.97395833],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97849462, 0.02150538],\n",
              "       [0.96195652, 0.03804348],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00564972, 0.99435028],\n",
              "       [0.28804348, 0.71195652],\n",
              "       [0.92777778, 0.07222222],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96132597, 0.03867403],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.63218391, 0.36781609],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.11666667, 0.88333333],\n",
              "       [0.99473684, 0.00526316],\n",
              "       [0.        , 1.        ],\n",
              "       [0.34615385, 0.65384615],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.21142857, 0.78857143],\n",
              "       [0.33516484, 0.66483516],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01123596, 0.98876404],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.00505051, 0.99494949],\n",
              "       [0.98192771, 0.01807229],\n",
              "       [0.91256831, 0.08743169],\n",
              "       [0.99415205, 0.00584795],\n",
              "       [0.98275862, 0.01724138],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03243243, 0.96756757],\n",
              "       [0.98378378, 0.01621622],\n",
              "       [0.01176471, 0.98823529],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01052632, 0.98947368],\n",
              "       [0.98850575, 0.01149425],\n",
              "       [0.7679558 , 0.2320442 ],\n",
              "       [0.44329897, 0.55670103],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.71005917, 0.28994083],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.91803279, 0.08196721],\n",
              "       [1.        , 0.        ],\n",
              "       [0.65445026, 0.34554974],\n",
              "       [0.11666667, 0.88333333],\n",
              "       [0.67741935, 0.32258065],\n",
              "       [0.93103448, 0.06896552],\n",
              "       [0.        , 1.        ],\n",
              "       [0.15463918, 0.84536082],\n",
              "       [0.87647059, 0.12352941],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03723404, 0.96276596],\n",
              "       [0.02890173, 0.97109827],\n",
              "       [0.2460733 , 0.7539267 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.88829787, 0.11170213],\n",
              "       [0.005     , 0.995     ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.25      , 0.75      ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00510204, 0.99489796],\n",
              "       [0.        , 1.        ],\n",
              "       [0.94358974, 0.05641026],\n",
              "       [0.75      , 0.25      ],\n",
              "       [0.01052632, 0.98947368],\n",
              "       [1.        , 0.        ],\n",
              "       [0.20994475, 0.79005525],\n",
              "       [0.65079365, 0.34920635],\n",
              "       [0.        , 1.        ],\n",
              "       [0.05747126, 0.94252874],\n",
              "       [0.50543478, 0.49456522],\n",
              "       [0.99447514, 0.00552486],\n",
              "       [0.0199005 , 0.9800995 ],\n",
              "       [0.99462366, 0.00537634],\n",
              "       [0.23295455, 0.76704545],\n",
              "       [0.48125   , 0.51875   ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.02439024, 0.97560976],\n",
              "       [0.98863636, 0.01136364],\n",
              "       [0.30102041, 0.69897959],\n",
              "       [0.8957346 , 0.1042654 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.78723404, 0.21276596],\n",
              "       [1.        , 0.        ],\n",
              "       [0.02352941, 0.97647059],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99435028, 0.00564972],\n",
              "       [1.        , 0.        ],\n",
              "       [0.9893617 , 0.0106383 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96618357, 0.03381643],\n",
              "       [0.99428571, 0.00571429],\n",
              "       [0.02072539, 0.97927461],\n",
              "       [0.25294118, 0.74705882],\n",
              "       [0.96195652, 0.03804348],\n",
              "       [0.2962963 , 0.7037037 ],\n",
              "       [0.99514563, 0.00485437],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00543478, 0.99456522],\n",
              "       [0.72972973, 0.27027027],\n",
              "       [0.42196532, 0.57803468],\n",
              "       [0.45      , 0.55      ],\n",
              "       [0.90860215, 0.09139785],\n",
              "       [0.90710383, 0.09289617],\n",
              "       [0.02234637, 0.97765363],\n",
              "       [0.82198953, 0.17801047],\n",
              "       [0.00529101, 0.99470899],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01685393, 0.98314607],\n",
              "       [0.97752809, 0.02247191],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01530612, 0.98469388],\n",
              "       [0.        , 1.        ],\n",
              "       [0.0106383 , 0.9893617 ],\n",
              "       [0.00526316, 0.99473684],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95675676, 0.04324324],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.39108911, 0.60891089],\n",
              "       [0.34536082, 0.65463918],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.28729282, 0.71270718],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98958333, 0.01041667],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98453608, 0.01546392],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.68823529, 0.31176471],\n",
              "       [0.93010753, 0.06989247],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98895028, 0.01104972],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.04918033, 0.95081967],\n",
              "       [1.        , 0.        ],\n",
              "       [0.04891304, 0.95108696],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02094241, 0.97905759],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95480226, 0.04519774],\n",
              "       [0.78074866, 0.21925134],\n",
              "       [0.61256545, 0.38743455],\n",
              "       [0.        , 1.        ],\n",
              "       [0.15909091, 0.84090909],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95604396, 0.04395604],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.42937853, 0.57062147],\n",
              "       [0.82857143, 0.17142857],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99470899, 0.00529101],\n",
              "       [0.01724138, 0.98275862],\n",
              "       [0.00546448, 0.99453552],\n",
              "       [0.99487179, 0.00512821],\n",
              "       [0.        , 1.        ],\n",
              "       [0.26923077, 0.73076923],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97752809, 0.02247191],\n",
              "       [0.79695431, 0.20304569],\n",
              "       [0.99431818, 0.00568182],\n",
              "       [0.        , 1.        ],\n",
              "       [0.0931677 , 0.9068323 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03108808, 0.96891192],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03157895, 0.96842105],\n",
              "       [1.        , 0.        ],\n",
              "       [0.79545455, 0.20454545],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.92857143, 0.07142857],\n",
              "       [0.98913043, 0.01086957],\n",
              "       [0.19161677, 0.80838323],\n",
              "       [0.21827411, 0.78172589],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.19354839, 0.80645161],\n",
              "       [0.95930233, 0.04069767],\n",
              "       [0.01621622, 0.98378378],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98823529, 0.01176471],\n",
              "       [0.        , 1.        ],\n",
              "       [0.51086957, 0.48913043],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00561798, 0.99438202],\n",
              "       [0.        , 1.        ],\n",
              "       [0.08040201, 0.91959799],\n",
              "       [0.12      , 0.88      ],\n",
              "       [0.97916667, 0.02083333],\n",
              "       [0.01      , 0.99      ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.43646409, 0.56353591],\n",
              "       [0.15300546, 0.84699454],\n",
              "       [0.57647059, 0.42352941],\n",
              "       [0.60526316, 0.39473684],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.63917526, 0.36082474],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.26519337, 0.73480663],\n",
              "       [0.83251232, 0.16748768],\n",
              "       [0.05      , 0.95      ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.82967033, 0.17032967],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00574713, 0.99425287],\n",
              "       [0.11340206, 0.88659794],\n",
              "       [0.01630435, 0.98369565],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98947368, 0.01052632],\n",
              "       [0.89340102, 0.10659898],\n",
              "       [0.20670391, 0.79329609],\n",
              "       [0.96319018, 0.03680982],\n",
              "       [0.        , 1.        ],\n",
              "       [0.56756757, 0.43243243],\n",
              "       [0.03409091, 0.96590909],\n",
              "       [0.97740113, 0.02259887],\n",
              "       [0.82439024, 0.17560976],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99459459, 0.00540541],\n",
              "       [0.93956044, 0.06043956],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.23033708, 0.76966292],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.86842105, 0.13157895],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.72820513, 0.27179487],\n",
              "       [0.94845361, 0.05154639],\n",
              "       [1.        , 0.        ],\n",
              "       [0.73743017, 0.26256983],\n",
              "       [0.46753247, 0.53246753],\n",
              "       [0.        , 1.        ],\n",
              "       [0.91089109, 0.08910891],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.83243243, 0.16756757],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.77647059, 0.22352941],\n",
              "       [0.11731844, 0.88268156],\n",
              "       [0.44086022, 0.55913978],\n",
              "       [0.27179487, 0.72820513],\n",
              "       [0.        , 1.        ],\n",
              "       [0.90909091, 0.09090909],\n",
              "       [0.80113636, 0.19886364],\n",
              "       [0.00507614, 0.99492386],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99481865, 0.00518135],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00537634, 0.99462366],\n",
              "       [0.95263158, 0.04736842],\n",
              "       [0.97714286, 0.02285714],\n",
              "       [1.        , 0.        ],\n",
              "       [0.5027933 , 0.4972067 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00512821, 0.99487179],\n",
              "       [0.99418605, 0.00581395],\n",
              "       [0.00505051, 0.99494949],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97206704, 0.02793296],\n",
              "       [0.        , 1.        ],\n",
              "       [0.04046243, 0.95953757],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.0052356 , 0.9947644 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.12643678, 0.87356322],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.45508982, 0.54491018],\n",
              "       [0.06486486, 0.93513514],\n",
              "       [0.18292683, 0.81707317],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.21782178, 0.78217822],\n",
              "       [0.98285714, 0.01714286],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00571429, 0.99428571],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97382199, 0.02617801],\n",
              "       [0.27325581, 0.72674419],\n",
              "       [0.99465241, 0.00534759],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98924731, 0.01075269],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02392344, 0.97607656],\n",
              "       [0.9800995 , 0.0199005 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03191489, 0.96808511],\n",
              "       [0.70114943, 0.29885057]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Random patches method - sampling both training instances and features -includes use of 2 kep hyper parameters - max_features and bootstrap_features\n",
        "\n",
        "2.Random subspaces method - keeping all training instances but sampling features \n",
        "\n"
      ],
      "metadata": {
        "id": "ci5BMjphIeO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forests"
      ],
      "metadata": {
        "id": "_Y2UjGl9Isr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "MKWgGD3-FjBf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = 1)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "DCA-PyOzI9Z5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_features = \"auto\", max_leaf_nodes = 16), n_estimators = 500, max_samples = 1.0, bootstrap = True, n_jobs = -1)"
      ],
      "metadata": {
        "id": "xkruQDjUJOQC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance - relative impotance of each feature\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators = 500, n_jobs = -1)\n",
        "rnd_clf.fit(iris['data'], iris['target'])\n",
        "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_):\n",
        "  print(name, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMj_-MkvJsaO",
        "outputId": "c6afa307-b22f-473f-d510-8da59a5e91ff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.1059020727323791\n",
            "sepal width (cm) 0.023519136593076948\n",
            "petal length (cm) 0.4369261110999872\n",
            "petal width (cm) 0.43365267957455683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boosting - ensemble that combines several weak learners into a strong learner\n",
        "\n",
        "Boosting method - is to train predictors sequentially, each trying to correct its predecessor.\n",
        "\n",
        "1. Adaboosting - Adaptive Boosting\n",
        "\n",
        "Correct predecessor by paying more attention to training instances that the predecessor underfitted.\n",
        "Algo trains a base classifier( decision tree) and uses it to make predictions on training set. Then algo increases relative weight of missclassified training instances and train next classifier with updated weights.\n",
        "\n",
        "2. Gradient Boosting\n",
        "\n",
        "Unlike AdaBoosting, Gradient boosting tries to fit the new predictor to residual errors made by the predecessor.\n"
      ],
      "metadata": {
        "id": "7JcxAxP8NDJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 1), n_estimators = 200, algorithm = \"SAMME.R\", learning_rate=0.5)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf6cNB5NM3o3",
        "outputId": "0c475576-84f9-4793-84b8-48a09980d9e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   learning_rate=0.5, n_estimators=200)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100,1)-0.5\n",
        "y = 3*X[:, 0]**2 +0.05*np.random.randn(100)"
      ],
      "metadata": {
        "id": "eaQmxtT9STYm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth =2)\n",
        "tree_reg1.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYMMBJkbQaTJ",
        "outputId": "5647cb12-023e-4c58-ea40-5994089fee14"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training next predictor using residual errors of tree_reg1\n",
        "\n",
        "y2 = y- tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth = 2)\n",
        "tree_reg2.fit(X,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kxD3m61REhx",
        "outputId": "99a5d06b-215d-4891-caec-c59a0825ceb7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3 = y2- tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth = 2)\n",
        "tree_reg3.fit(X,y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY0H14m4Rb6p",
        "outputId": "a1010dd1-9cd5-40d8-da27-1d33aba2d46a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = np.array([[0.8]])"
      ],
      "metadata": {
        "id": "c7Vc3yG2Spuj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n"
      ],
      "metadata": {
        "id": "MMcPe1PJRlj3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GyQWLniSoHs",
        "outputId": "064bfb9e-0feb-461f-e52a-058a833d7925"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.76670256])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 3, random_state = 42)\n",
        "gbrt.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hEjqMObS2yZ",
        "outputId": "118a8e58-a334-4a34-adc4-58d57f4b641e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=3, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
        "\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 120)\n",
        "gbrt.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuVxjoI9TK4V",
        "outputId": "a0bd1343-cedd-41e1-dbf9-209486812652"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=120)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
        "bst_n_estimators = np.argmin(errors) +1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth = 2, n_estimators = bst_n_estimators)\n",
        "gbrt_best.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR_B1UeZXO5F",
        "outputId": "740dcc3f-80eb-4281-baf4-0e8afc046559"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=110)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stochastic gradient boosting\n",
        "gbrt = GradientBoostingRegressor(max_depth = 2, warm_start = True)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "\n",
        "for n_estimators in range(1, 120):\n",
        "  gbrt.n_estimators = n_estimators\n",
        "  gbrt.fit(X_train, y_train)\n",
        "  y_pred = gbrt.predict(X_val)\n",
        "  val_error = mean_squared_error(y_val, y_pred)\n",
        "\n",
        "  if val_error< min_val_error:\n",
        "    min_val_error = val_error\n",
        "    error_going_up = 0\n",
        "\n",
        "  else:\n",
        "    error_going_up +=1\n",
        "    if error_going_up ==5:\n",
        "      break"
      ],
      "metadata": {
        "id": "Ns0teKeYXyL1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gbrt.n_estimators)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu34VhHoYrw3",
        "outputId": "d16bd5af-5455-45c6-a7ce-87b75437d6a1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"min validation MSE\", min_val_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TryT8hUiY2AT",
        "outputId": "82c7a118-2738-4651-bca1-cfb0188a3531"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min validation MSE 0.0028209980081892543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using XGBoost\n",
        "\n",
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYu4T6yHY8RD",
        "outputId": "d2e0625a-cec6-4985-b77e-0b02cb98de3f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:41:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or try this\n",
        "xgb_reg.fit(X_train, y_train, eval_set = [(X_val, y_val)], early_stopping_rounds = 2)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAzPlPa7ZvZ-",
        "outputId": "8711b349-0822-4a79-9708-b8353bcd76a4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:43:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:0.252919\n",
            "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
            "[1]\tvalidation_0-rmse:0.22967\n",
            "[2]\tvalidation_0-rmse:0.208932\n",
            "[3]\tvalidation_0-rmse:0.190537\n",
            "[4]\tvalidation_0-rmse:0.174254\n",
            "[5]\tvalidation_0-rmse:0.159642\n",
            "[6]\tvalidation_0-rmse:0.146745\n",
            "[7]\tvalidation_0-rmse:0.134787\n",
            "[8]\tvalidation_0-rmse:0.123794\n",
            "[9]\tvalidation_0-rmse:0.11347\n",
            "[10]\tvalidation_0-rmse:0.10435\n",
            "[11]\tvalidation_0-rmse:0.095989\n",
            "[12]\tvalidation_0-rmse:0.0889\n",
            "[13]\tvalidation_0-rmse:0.083319\n",
            "[14]\tvalidation_0-rmse:0.078312\n",
            "[15]\tvalidation_0-rmse:0.073715\n",
            "[16]\tvalidation_0-rmse:0.06965\n",
            "[17]\tvalidation_0-rmse:0.06641\n",
            "[18]\tvalidation_0-rmse:0.063814\n",
            "[19]\tvalidation_0-rmse:0.061651\n",
            "[20]\tvalidation_0-rmse:0.05997\n",
            "[21]\tvalidation_0-rmse:0.058577\n",
            "[22]\tvalidation_0-rmse:0.057521\n",
            "[23]\tvalidation_0-rmse:0.056667\n",
            "[24]\tvalidation_0-rmse:0.055901\n",
            "[25]\tvalidation_0-rmse:0.055247\n",
            "[26]\tvalidation_0-rmse:0.054666\n",
            "[27]\tvalidation_0-rmse:0.054397\n",
            "[28]\tvalidation_0-rmse:0.054156\n",
            "[29]\tvalidation_0-rmse:0.053898\n",
            "[30]\tvalidation_0-rmse:0.053815\n",
            "[31]\tvalidation_0-rmse:0.053535\n",
            "[32]\tvalidation_0-rmse:0.053257\n",
            "[33]\tvalidation_0-rmse:0.052872\n",
            "[34]\tvalidation_0-rmse:0.052825\n",
            "[35]\tvalidation_0-rmse:0.052712\n",
            "[36]\tvalidation_0-rmse:0.052528\n",
            "[37]\tvalidation_0-rmse:0.052429\n",
            "[38]\tvalidation_0-rmse:0.052297\n",
            "[39]\tvalidation_0-rmse:0.052404\n",
            "[40]\tvalidation_0-rmse:0.052358\n",
            "Stopping. Best iteration:\n",
            "[38]\tvalidation_0-rmse:0.052297\n",
            "\n"
          ]
        }
      ]
    }
  ]
}