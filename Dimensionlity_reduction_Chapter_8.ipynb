{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dimensionlity reduction Chapter 8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOuCfoIGlQwDI1owD5D9KGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AashiDutt/Hands-on-Machine-Learning-with-sklearn-keras-and-tensorflow/blob/main/Dimensionlity_reduction_Chapter_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality reduction techniques\n",
        "\n",
        "1. PCA - Principal Component Analysis\n",
        "   First identifies the plane, then projects data onto it.\n",
        "\n",
        "   In short the axis that minimizes the mean squared distance between the orignal dataset and its projection onto that axis."
      ],
      "metadata": {
        "id": "i-q_J_Ooimov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ahZvbWY57EOG"
      },
      "outputs": [],
      "source": [
        "# Finding Principal Components\n",
        "# Using Singular Value Decomposition - \n",
        "#decomposes the matrix X into matix multiplication of 3 matrices \n",
        "#(U SIGMA V) where V contains the unit vector that define all the principal components\n",
        "\n",
        "# Lets create a 3D dataset\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(4)\n",
        "\n",
        "m = 60\n",
        "w1, w2 = 0.1, 0.3\n",
        "noise = 0.1\n",
        "\n",
        "angles = np.random.rand(m) * 3*np.pi/2-0.5\n",
        "X = np.empty((m,3))\n",
        "X[:, 0] = np.cos(angles) +np.sin(angles)/2 + noise * np.random.randn(m)/2\n",
        "X[:, 1] = np.sin(angles) +0.7+ noise * np.random.randn(m)/2\n",
        "X[:, 2] = X[:,0] *w1 +X[:,1] *w2 + noise * np.random.randn(m)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Centering the data around origin\n",
        "X_centered = X -X.mean(axis =0)\n",
        "U,s,Vt = np.linalg.svd(X_centered)\n",
        "c1 = Vt.T[:, 0] # component 1\n",
        "c2 = Vt.T[:,1] # component 2"
      ],
      "metadata": {
        "id": "C_1PAbmzmqEU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Projecting training set onto the plane defined by first two pricipal components to reduce dimesionality down to any no. of dimensions while preserving the variance as much as possible\n",
        "W2 = Vt.T[:,:2]\n",
        "X2D = X_centered.dot(W2)\n",
        "X2D[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AKX1UH8ne3k",
        "outputId": "f91d6e56-cfef-46fe-ed2b-c9f48bc48271"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.50202733, -0.44169998],\n",
              "       [ 0.24659144,  0.48321221],\n",
              "       [-1.40746895, -0.40506286],\n",
              "       [-0.81513127,  0.47807754],\n",
              "       [-0.65530869,  0.40920943]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PCA using Sklearn"
      ],
      "metadata": {
        "id": "_TxsCjWlp2Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA using sklearn\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 2) #c1, c2\n",
        "X2D = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "4tCPlUbsohKw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2D[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nf0S219pamQ",
        "outputId": "596f7f54-42f9-43d4-ca54-5054bd3f75d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.50202733,  0.44169998],\n",
              "       [-0.24659144, -0.48321221],\n",
              "       [ 1.40746895,  0.40506286],\n",
              "       [ 0.81513127, -0.47807754],\n",
              "       [ 0.65530869, -0.40920943]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ratio indicates the proportion of dataset's variance that lies along each principal component\n",
        "\n",
        "pca.explained_variance_ratio_ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jby-Ys4Xpktj",
        "outputId": "0ad45166-5a63-4040-ed52-661bbb729f02"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.77778267, 0.21304902])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows that 77% of datasets variance lies along 1st principal component(PC), 21% along 2nd PC and rest along 3rd PC i.e it contains least info\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PTv6DtttrWpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing right number of Dimensions"
      ],
      "metadata": {
        "id": "nBBn3BfWrY4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version =1, as_frame = False)\n",
        "mnist.target = mnist.target.astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "85LIh82qqDHT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = mnist[\"data\"]\n",
        "y = mnist['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
        "\n"
      ],
      "metadata": {
        "id": "V1pPPEZxr14b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "d = np.argmax(cumsum >= 0.95) +1 # dimesnions"
      ],
      "metadata": {
        "id": "R0PKj_6psQWy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8Hrc2vqsfMZ",
        "outputId": "75eca9dc-9a45-4ad0-dc22-0941f05fb7a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 0.95)\n",
        "X_reduced = pca.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "dn9f0VXusfzw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse the dimensionality reduction\n",
        "\n",
        "pca = PCA(n_components = 154)\n",
        "X_reduced = pca.fit_transform(X_train)\n",
        "X_recovered = pca.inverse_transform(X_reduced)"
      ],
      "metadata": {
        "id": "IKRslEVHs3mM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Not all data will be recovered\n",
        "\n",
        "# Randomized PCA\n",
        "rnd_pca = PCA(n_components = 154, svd_solver = 'randomized')\n",
        "X_reduced = rnd_pca.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "mPj7Gcf3tdOx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incremental PCA - split large training sets into mini batches and apply PCA online\n",
        "\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "n_batches = 100\n",
        "inc_pca = IncrementalPCA(n_components = 154)\n",
        "\n",
        "for X_batch in np.array_split(X_train, n_batches):\n",
        "  inc_pca.partial_fit(X_batch)\n",
        "\n",
        "X_reduced = inc_pca.transform(X_train)"
      ],
      "metadata": {
        "id": "T8UeJjhxuHv0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kernel PCA - same as Kernel trick\n",
        "\n",
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "rbf_pca = KernelPCA(n_components = 2, kernel = 'rbf', gamma = 0.04)\n",
        "X_reduced = rbf_pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "ws3XP2AgvEIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use grid search to find best kernel and hyperparameter for best performance\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "clf = Pipeline([\n",
        "    (\"kpca\", KernelPCA(n_components = 2)),\n",
        "    (\"log_reg\", LogisticRegression())\n",
        "])\n",
        "\n",
        "param_grid = [{\n",
        "    \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
        "    \"kpca__kernel\":[\"rbf\", \"sigmoid\"]\n",
        "}]\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv = 3)\n",
        "grid_search.fit(X,y)\n",
        "\n",
        "print(grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "s8z7rWg4vo5-",
        "outputId": "974b7c56-bcc3-4aa0-875f-a45425ca36e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9942d703f0cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m clf = Pipeline([\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"kpca\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKernelPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"log_reg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m ])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KernelPCA' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rbf_pca = KernelPCA(n_components = 2, kernel = \"rbf\", gamma = 0.0433, fit_inverse_transform=True)\n",
        "X_reduced = rbf.fit_transform(X)\n",
        "X_preimage= rbf_pca.inverse_transform(X_reduced)"
      ],
      "metadata": {
        "id": "1UcUHbJwxML8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(X, X_reduced)"
      ],
      "metadata": {
        "id": "OM-tCu4qyK35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLE - Locally Linear Embedding\n",
        "\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "\n",
        "lle = LocallyLinearEmbedding(n_components = 2, n_neighbors= 10)\n",
        "X_reduced = lle.fit_transform(X)"
      ],
      "metadata": {
        "id": "hFjJZIBtykcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}